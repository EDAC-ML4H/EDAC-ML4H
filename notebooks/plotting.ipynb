{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_theme(\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_results(results_dir, model, runs, suffix=''):\n",
    "    const_results = []\n",
    "    poly_results = []\n",
    "    pruning_percentages = None\n",
    "\n",
    "    for i in range(runs):\n",
    "        \n",
    "        file_name = Path(results_dir) / model / f'{model}_const/{i}/{model}_constant_sparsity_results{suffix}.json'\n",
    "        with open(file_name) as f:\n",
    "            pruning_percentages, results = parse_results_file(json.load(f))\n",
    "            const_results.append(results)\n",
    "        file_name = Path(results_dir) / model / f'{model}_poly/{i}/{model}_polynomial_decay_results{suffix}.json'\n",
    "        with open(file_name) as f:\n",
    "            pruning_percentages, results = parse_results_file(json.load(f))\n",
    "            poly_results.append(results)\n",
    "\n",
    "    return const_results, poly_results, pruning_percentages\n",
    "\n",
    "def parse_results_file(results):\n",
    "\n",
    "    pruning_percentages = []\n",
    "    results_dict = {\"baseline\": {\"aucs\":[], \"inf_time\": [], \"size\": []},\n",
    "            \"int8\": {\"aucs\":[], \"inf_time\": [], \"size\": []},\n",
    "            \"float16\": {\"aucs\":[], \"inf_time\": [], \"size\": []}\n",
    "    }\n",
    "\n",
    "    for percentage, result in results.items():\n",
    "        pruning_percentages.append(float(percentage))\n",
    "        \n",
    "        results_dict[\"baseline\"][\"aucs\"].append(float(result[\"default\"][\"auc\"]))\n",
    "        results_dict[\"baseline\"][\"inf_time\"].append(float(result[\"default\"][\"inf_time\"]))\n",
    "        results_dict[\"baseline\"][\"size\"].append(float(result[\"default\"][\"size\"]))\n",
    "\n",
    "        results_dict[\"int8\"][\"aucs\"].append(float(result[\"int8\"][\"auc\"]))\n",
    "        results_dict[\"int8\"][\"inf_time\"].append(float(result[\"int8\"][\"inf_time\"]))\n",
    "        results_dict[\"int8\"][\"size\"].append(float(result[\"int8\"][\"size\"]))\n",
    "\n",
    "        results_dict[\"float16\"][\"aucs\"].append(float(result[\"float16\"][\"auc\"]))\n",
    "        results_dict[\"float16\"][\"inf_time\"].append(float(result[\"float16\"][\"inf_time\"]))\n",
    "        results_dict[\"float16\"][\"size\"].append(float(result[\"float16\"][\"size\"]))\n",
    "    \n",
    "    return np.array(pruning_percentages) * 100, results_dict\n",
    "\n",
    "def get_mean_std(results, quantization, metric):\n",
    "    values = []\n",
    "    for result in results:\n",
    "        values.append(np.array(result[quantization][metric]))\n",
    "    \n",
    "    values = np.array(values)\n",
    "    mean = values.mean(axis=0)\n",
    "    std = values.std(axis=0)\n",
    "    \n",
    "    return mean, std\n",
    "    \n",
    "def plot_pruning(pruning_percentages, const_results, poly_results, file_name=None):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1,3, sharex= True, figsize=(12,3))\n",
    "    \n",
    "    aucs_mean, aucs_std = get_mean_std(const_results, 'baseline', 'aucs')\n",
    "    const_aucs = ax1.plot(pruning_percentages, aucs_mean)\n",
    "    ax1.fill_between(pruning_percentages, aucs_mean-aucs_std, aucs_mean+aucs_std, alpha=0.3)\n",
    "    ### Patch for legend\n",
    "    const_aucs_fill = ax1.fill(np.NaN, np.NaN, 'b', alpha=0.3)\n",
    "    \n",
    "    aucs_mean, aucs_std = get_mean_std(poly_results, 'baseline', 'aucs')\n",
    "    poly_aucs = ax1.plot(pruning_percentages, aucs_mean)\n",
    "    ax1.fill_between(pruning_percentages, aucs_mean-aucs_std, aucs_mean+aucs_std, alpha=0.3)\n",
    "    poly_aucs_fill = ax1.fill(np.NaN, np.NaN, 'tab:orange', alpha=0.3)\n",
    "    \n",
    "    ax1.set_ylim([0,1])\n",
    "    ax1.set_ylabel(\"AUC Score\")\n",
    "    \n",
    "    ax1.legend([(const_aucs_fill[0], const_aucs[0]), (poly_aucs_fill[0], poly_aucs[0])],\n",
    "               [\"Const.\", \"Poly. Decay\"],\n",
    "               loc='lower left')\n",
    "    \n",
    "    sizes_mean, sizes_std = get_mean_std(const_results, 'baseline', 'size')\n",
    "    const_sizes = ax2.plot(pruning_percentages, sizes_mean)\n",
    "    const_sizes = ax2.fill_between(pruning_percentages, sizes_mean-sizes_std, sizes_mean+sizes_std, alpha=0.3)\n",
    "    sizes_mean, sizes_std = get_mean_std(poly_results, 'baseline', 'size')\n",
    "    poly_sizes = ax2.errorbar(pruning_percentages, sizes_mean)\n",
    "    poly_sizes = ax2.fill_between(pruning_percentages, sizes_mean-sizes_std, sizes_mean+sizes_std, alpha=0.3)\n",
    "    ax2.set_ylabel(\"Gzipped Model Size (MB)\")\n",
    "    \n",
    "    inf_mean, inf_std = get_mean_std(const_results, 'baseline', 'inf_time')\n",
    "    inf_mean = inf_mean*1000\n",
    "    inf_std = inf_std*1000\n",
    "    const_inf =  ax3.plot(pruning_percentages, inf_mean)\n",
    "    const_inf = ax3.fill_between(pruning_percentages, inf_mean-inf_std, inf_mean+inf_std, alpha=0.3)\n",
    "    inf_mean, inf_std = get_mean_std(poly_results, 'baseline', 'inf_time')\n",
    "    inf_mean = inf_mean*1000\n",
    "    inf_std = inf_std*1000\n",
    "    poly_inf =  ax3.plot(pruning_percentages, inf_mean)\n",
    "    poly_inf = ax3.fill_between(pruning_percentages, inf_mean-inf_std, inf_mean+inf_std, alpha=0.3)\n",
    "    ax3.set_ylabel(\"Inference Time (ms)\")\n",
    "\n",
    "    fig.text(0.5, 0.0001, 'Pruning Percentage (%)', ha='center')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if file_name:\n",
    "        plt.savefig(file_name, bbox_inches='tight')\n",
    "    \n",
    "def plot_quantization(pruning_percentages, results, file_name=None):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1,3, sharex= True, figsize=(12,3))\n",
    "\n",
    "    \n",
    "    int8_aucs_mean, int8_aucs_std = get_mean_std(results, 'int8', 'aucs')\n",
    "    int8_aucs = ax1.plot(pruning_percentages, int8_aucs_mean)\n",
    "    ax1.fill_between(pruning_percentages, int8_aucs_mean-int8_aucs_std, int8_aucs_mean+int8_aucs_std, alpha=0.3)\n",
    "    int8_aucs_fill = ax1.fill(np.NaN, np.NaN, 'b', alpha=0.3)\n",
    "\n",
    "    float16_aucs_mean, float16_aucs_std = get_mean_std(results, 'float16', 'aucs')\n",
    "    float16_aucs = ax1.plot(pruning_percentages, float16_aucs_mean)\n",
    "    ax1.fill_between(pruning_percentages, float16_aucs_mean-float16_aucs_std, float16_aucs_mean+float16_aucs_std, alpha=0.3)\n",
    "    float16_aucs_fill = ax1.fill(np.NaN, np.NaN, 'tab:orange', alpha=0.3)\n",
    "\n",
    "    ax1.set_ylim([0,1])\n",
    "    \n",
    "    ax1.set_ylabel(\"AUC Score\")\n",
    "    ax1.legend([(int8_aucs_fill[0], int8_aucs[0]), (float16_aucs_fill[0], float16_aucs[0])],\n",
    "               [\"Int8\", \"Float16\"],\n",
    "               loc='lower left')\n",
    "    int8_size_mean, int8_size_std = get_mean_std(results, 'int8', 'size')\n",
    "    int8_size = ax2.plot(pruning_percentages, int8_size_mean)\n",
    "    int8_size = ax2.fill_between(pruning_percentages, int8_size_mean-int8_size_std, int8_size_mean+int8_size_std, alpha=0.3)\n",
    "    float16_size_mean, float16_size_std = get_mean_std(results, 'float16', 'size')\n",
    "    float16_size = ax2.plot(pruning_percentages, float16_size_mean)\n",
    "    float16_size = ax2.fill_between(pruning_percentages, float16_size_mean-float16_size_std, float16_size_mean+float16_size_std, alpha=0.3)\n",
    "    ax2.set_ylabel(\"Gzipped Model Size (MB)\")\n",
    "\n",
    "\n",
    "    int8_inf_mean, int8_inf_std = get_mean_std(results, 'int8', 'inf_time')\n",
    "    int8_inf_mean = int8_inf_mean*1000\n",
    "    int8_inf_std = int8_inf_std*1000\n",
    "    int8_inf = ax3.plot(pruning_percentages, int8_inf_mean)\n",
    "    int8_inf = ax3.fill_between(pruning_percentages, int8_inf_mean-int8_inf_std, int8_inf_mean+int8_inf_std, alpha=0.3)\n",
    "    float16_inf_mean, float16_inf_std = get_mean_std(results, 'float16', 'inf_time')\n",
    "    float16_inf_mean = float16_inf_mean *1000\n",
    "    float16_inf_std = float16_inf_std * 1000\n",
    "    float16_inf = ax3.plot(pruning_percentages, float16_inf_mean)\n",
    "    float16_inf = ax3.fill_between(pruning_percentages, float16_inf_mean-float16_inf_std,float16_inf_mean+float16_inf_std,alpha=0.3)\n",
    "    ax3.set_ylabel(\"Inference Time (ms)\")\n",
    "\n",
    "    fig.text(0.5, 0.0001, 'Pruning Percentage (%)', ha='center')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if file_name:\n",
    "        plt.savefig(file_name, bbox_inches='tight')\n",
    "\n",
    "def generate_table(percentages, results):\n",
    "    aucs_mean, aucs_std = get_mean_std(results, 'baseline', 'aucs')\n",
    "    int8_aucs_mean, int8_aucs_std = get_mean_std(results, 'int8', 'aucs')\n",
    "    float16_aucs_mean, float16_aucs_std = get_mean_std(results, 'float16', 'aucs')\n",
    "\n",
    "    sizes_mean, sizes_std = get_mean_std(results, 'baseline', 'size')\n",
    "    int8_size_mean, int8_size_std = get_mean_std(results, 'int8', 'size')\n",
    "    float16_size_mean, float16_size_std = get_mean_std(results, 'float16', 'size')\n",
    "\n",
    "    inf_mean, inf_std = get_mean_std(results, 'baseline', 'inf_time')\n",
    "    int8_inf_mean, int8_inf_std = get_mean_std(results, 'int8', 'inf_time')\n",
    "    float16_inf_mean, float16_inf_std = get_mean_std(results, 'float16', 'inf_time')\n",
    "\n",
    "    inf_mean, inf_std = inf_mean*1000, inf_std*1000\n",
    "    int8_inf_mean, int8_inf_std = int8_inf_mean*1000, int8_inf_std*1000\n",
    "    float16_inf_mean, float16_inf_std = float16_inf_mean*1000, float16_inf_std*1000\n",
    "    \n",
    "    # Sparsity & AUC & Compressed Model Size (MB) & Inference Time (s) & 8-Bit  Model Size & 8-Bit Inference Time & 16-Bit Model Size & 16-Bit Inference Time \\\\\n",
    "    for percent, auc, auc_dev, auc8, auc8_dev,  auc16, auc16_dev, cms, cms_dev, cms8, cms8_dev, cms16, cms16_dev, it, it_dev, it8, it8_dev, it16, it16_dev in zip(percentages, aucs_mean, aucs_std, int8_aucs_mean, int8_aucs_std, float16_aucs_mean, float16_aucs_std, sizes_mean, sizes_std, int8_size_mean, int8_size_std, float16_size_mean, float16_size_std, inf_mean, inf_std,  int8_inf_mean, int8_inf_std, float16_inf_mean, float16_inf_std):\n",
    "        string_to_output = f\"{float(percent):.1f} & {auc:.3f} $\\pm$ {auc_dev:.3f} & {auc8:.3f} $\\pm$ {auc8_dev:.3f} & {auc16:.3f} $\\pm$ {auc16_dev:.3f} & {cms:.3f} $\\pm$ {cms_dev:.3f} & {cms8:.3f} $\\pm$ {cms8_dev:.3f} & {cms16:.3f} $\\pm$ {cms16_dev:.3f} & {it:.3f} $\\pm$ {it_dev:.3f} & {it8:.3f}  $\\pm$ {it8_dev:.3f} & {it16:.3f} $\\pm$ {it16_dev:.3f} \\\\\\\\\"\n",
    "        print(string_to_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Brogrammers results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results directory\n",
    "results_dir = '../results/'\n",
    "model = 'brogrammers'\n",
    "runs = 20\n",
    "\n",
    "# Load results\n",
    "const_results, poly_results, pruning_percentages = load_results(results_dir, model, runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_table(pruning_percentages, const_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_table(pruning_percentages, poly_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pruning(pruning_percentages, const_results, poly_results, file_name='cnn_pruning_exps_all.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_quantization(pruning_percentages, poly_results, file_name='cnn_quant_exps_all.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results directory\n",
    "results_dir = '../results/'\n",
    "model = 'attention'\n",
    "runs = 5\n",
    "\n",
    "# Load results\n",
    "const_results, poly_results, pruning_percentages = load_results(results_dir, model, runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_table(pruning_percentages, const_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_table(pruning_percentages, poly_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pruning(pruning_percentages, const_results, poly_results, file_name='cnn_lstm_pruning_exps_all.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_quantization(pruning_percentages, poly_results, file_name='cnn_lstm_quant_exps_all.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
