{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed726cb2-4d23-4579-bc53-abaeb26d3a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import librosa.display\n",
    "import cv2\n",
    "import soundfile as sf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0e3070-ec7d-4137-8e24-72fa7e97b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "data_dir = '../coughvid-clean-silence-removed'\n",
    "meta_data_path = os.path.join(data_dir, 'meta_data.csv')\n",
    "meta_data = pd.read_csv(meta_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e0202f-7d21-4e19-9614-85f25cb51e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['uuid', 'cough_detected', 'age', 'gender', 'status']\n",
    "mask = meta_data['cough_detected']>=0.7\n",
    "meta_data = meta_data[mask][columns].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb496149-3526-475a-9d3f-393eab6f1650",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(meta_data['status'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae03ce9-ce71-49a9-98b5-9d34bdfbd24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data['label'] = meta_data['status'].isin(['COVID-19', 'symptomatic']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953d08ab-e9a9-47f1-9039-b312bd10d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = meta_data['uuid'].values\n",
    "labels = meta_data['label'].values\n",
    "ids.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802961c2-e502-45e0-9da5-adcdbd860ad0",
   "metadata": {},
   "source": [
    "### Split sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905d7ea-3647-4541-b096-14a4fda38ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b400a80d-0084-4993-b456-b2f25e84d545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for each set\n",
    "new_data_dir = '../coughvid_attention'\n",
    "train_dir = os.path.join(new_data_dir, 'train')\n",
    "valid_dir = os.path.join(new_data_dir, 'valid')\n",
    "test_dir = os.path.join(new_data_dir, 'test')\n",
    "\n",
    "make_dir(train_dir)\n",
    "make_dir(valid_dir)\n",
    "make_dir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa29896-1b5f-48a8-b322-652bef275223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create splits\n",
    "# 60:20:20 train:valid:test ratio\n",
    "ids_train, ids_test, labels_train, labels_test = train_test_split(ids,\n",
    "                                                                  labels,\n",
    "                                                                  test_size=0.2,\n",
    "                                                                  stratify=labels,\n",
    "                                                                  shuffle=True,\n",
    "                                                                  random_state=42)\n",
    "ids_train, ids_valid, labels_train, labels_valid = train_test_split(ids_train,\n",
    "                                                                    labels_train,\n",
    "                                                                    test_size=0.25,\n",
    "                                                                    stratify=labels_train,\n",
    "                                                                    shuffle=True,\n",
    "                                                                    random_state=41)\n",
    "\n",
    "ids_train.shape, ids_valid.shape, ids_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91d3c5b-a24a-4952-ad83-70754d163a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_name, labels in zip(['train', 'valid', 'test'], [labels_train, labels_valid, labels_test]):\n",
    "    print(f'{set_name:<5} :: {np.unique(labels, return_counts=True)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dca6752-d22e-40ee-87c9-f22b7347fe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_set(metadata:pd.DataFrame,\n",
    "                source_dir:str,\n",
    "                data_dir:str,\n",
    "                set_name:str,\n",
    "                set_ids):\n",
    "    \n",
    "    set_dir = os.path.join(data_dir, set_name)\n",
    "    target_dir = os.path.join(set_dir, 'recordings')\n",
    "    \n",
    "    make_dir(set_dir)\n",
    "    make_dir(target_dir)\n",
    "    \n",
    "    for uuid in tqdm(set_ids):\n",
    "        source_path = os.path.join(source_dir, f'{uuid}.wav')\n",
    "        \n",
    "        if not os.path.exists(source_path):\n",
    "            print(f'Missing :: {uuid}.wav')\n",
    "            continue\n",
    "            \n",
    "        target_path = os.path.join(target_dir, f'{uuid}.wav')\n",
    "        shutil.copy(source_path, target_path)\n",
    "    \n",
    "    # Save metadata for set\n",
    "    mask = metadata.uuid.isin(set_ids)\n",
    "    set_metadata = metadata[mask].copy().reset_index(drop=True)\n",
    "    metadata_path = os.path.join(set_dir, f'{set_name}_metadata.csv')\n",
    "    set_metadata.to_csv(metadata_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a2f59-269e-4382-aff4-0326ae4fd6aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coughvid_dir = os.path.join(data_dir, 'wavs-silence-removed')\n",
    "extract_set(meta_data, coughvid_dir, new_data_dir, 'train', ids_train)\n",
    "extract_set(meta_data, coughvid_dir, new_data_dir, 'valid', ids_valid)\n",
    "extract_set(meta_data, coughvid_dir, new_data_dir, 'test', ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1627dd-c4af-4d0d-b99f-9d1d0c44bd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_shift_set(data_dir, set_name):\n",
    "    \n",
    "    meta_data_path = os.path.join(data_dir, set_name, f'{set_name}_metadata.csv')\n",
    "    source_dir = os.path.join(data_dir, set_name, 'recordings')\n",
    "    target_dir = os.path.join(data_dir, set_name, 'augmented')\n",
    "    \n",
    "    make_dir(target_dir)\n",
    "\n",
    "    meta_data = pd.read_csv(meta_data_path)\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for uuid, label in tqdm(meta_data[['uuid', 'label']].values):\n",
    "        signal, sr = librosa.load(os.path.join(source_dir, f'{uuid}.wav'))\n",
    "        \n",
    "        if label:\n",
    "            sf.write(os.path.join(target_dir, f'sample{counter}_1.wav'), signal, sr, 'PCM_24')\n",
    "            counter+=1\n",
    "            pitch_shifting = librosa.effects.pitch_shift(signal, sr=sr, n_steps=-4)\n",
    "            sf.write(os.path.join(target_dir, f'sample{counter}_1.wav'), pitch_shifting, sr, 'PCM_24')\n",
    "            counter+=1\n",
    "        else:\n",
    "            sf.write(os.path.join(target_dir, f'sample{counter}_0.wav'), signal, sr, 'PCM_24')\n",
    "            counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeb6f5d-12ba-4f4d-a909-bfe97ac324a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_shift_set(new_data_dir, 'train')\n",
    "pitch_shift_set(new_data_dir, 'valid')\n",
    "pitch_shift_set(new_data_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e43433-4f33-449f-acd3-a38255197435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spect_augment_set(data_dir, set_name, param_masking=30):\n",
    "    \n",
    "    # Collect files to augment\n",
    "    aug_dir = os.path.join(data_dir, set_name, 'augmented')\n",
    "    files_regex = os.path.join(aug_dir, r'*.wav')\n",
    "    files = glob.glob(files_regex)\n",
    "    \n",
    "    # Create directory for melspectrograms\n",
    "    mels_path = os.path.join(data_dir, set_name, 'melspec')\n",
    "    make_dir(mels_path)\n",
    "    \n",
    "    # Path to save labels\n",
    "    labels_path = os.path.join(data_dir, set_name, f'{set_name}_labels.csv')\n",
    "    \n",
    "    y = []\n",
    "    count = 0\n",
    "    meanSignalLength = 156027\n",
    "    for fn in tqdm(files):\n",
    "        label = os.path.splitext(os.path.basename(fn))[0].split('_')[1]\n",
    "        signal , sr = librosa.load(fn)\n",
    "        s_len = len(signal)\n",
    "        \n",
    "        # Add zero padding to the signal if less than 156027 (~4.07 seconds)\n",
    "        if s_len < meanSignalLength:\n",
    "               pad_len = meanSignalLength - s_len\n",
    "               pad_rem = pad_len % 2\n",
    "               pad_len //= 2\n",
    "               signal = np.pad(signal, (pad_len, pad_len + pad_rem), 'constant', constant_values=0)\n",
    "        \n",
    "        # Remove from begining and the end if signal length is greater than 156027 (~4.07 seconds)\n",
    "        else:\n",
    "               pad_len = s_len - meanSignalLength\n",
    "               pad_len //= 2\n",
    "               signal = signal[pad_len:pad_len + meanSignalLength]\n",
    "\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=signal,\n",
    "                                                         sr=sr,\n",
    "                                                         n_mels=128,\n",
    "                                                         hop_length=512,\n",
    "                                                         fmax=8000,\n",
    "                                                         n_fft=512,\n",
    "                                                         center=True)\n",
    "        \n",
    "        dbscale_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max, top_db=80)\n",
    "        img = plt.imshow(dbscale_mel_spectrogram, interpolation='nearest',origin='lower')\n",
    "        plt.axis('off')\n",
    "        plt.savefig(os.path.join(mels_path, f'{count}.png'), bbox_inches='tight')\n",
    "        plt.close('all')\n",
    "        count+=1\n",
    "        \n",
    "        y.append(label)\n",
    "        if label == '1': # if COVID-19\n",
    "            freq_mask = tfio.audio.freq_mask(dbscale_mel_spectrogram, param=param_masking)\n",
    "            time_mask = tfio.audio.time_mask(freq_mask, param=param_masking)\n",
    "            img = plt.imshow(time_mask,origin='lower')\n",
    "            plt.axis('off')\n",
    "            plt.savefig(os.path.join(mels_path, f'{count}.png'), bbox_inches='tight')\n",
    "            plt.close('all')\n",
    "            count+=1\n",
    "            y.append(label)\n",
    "        \n",
    "        freq_mask = tfio.audio.freq_mask(dbscale_mel_spectrogram, param=param_masking)\n",
    "        time_mask = tfio.audio.time_mask(freq_mask, param=param_masking)\n",
    "        img = plt.imshow(time_mask,origin='lower')\n",
    "        plt.axis('off')\n",
    "        plt.savefig(os.path.join(mels_path, f'{count}.png'), bbox_inches='tight')\n",
    "        plt.close('all')\n",
    "        count+=1\n",
    "        y.append(label)\n",
    "    \n",
    "    # Save labels\n",
    "    y = pd.DataFrame(data={'label': y})\n",
    "    y.to_csv(labels_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f93f86-2ee7-4166-82e3-fcd8867865ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert False, 'Don\\'t run this in the notebook as it will crash. Run the spec_augment_sets.py script.'\n",
    "spect_augment_set(new_data_dir, 'train')\n",
    "spect_augment_set(new_data_dir, 'valid')\n",
    "spect_augment_set(new_data_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4378263c-021d-4275-aa62-620085a05ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_set(data_dir, set_name):\n",
    "    # Gather melspec files\n",
    "    path = os.path.join(data_dir, set_name, 'melspec')\n",
    "    names = sorted(os.listdir(path), key=lambda x: int(os.path.splitext(x)[0]))\n",
    "    \n",
    "    # Load images\n",
    "    img_array_size = (88,39)\n",
    "    images = []\n",
    "    for filename in tqdm(names):\n",
    "        img = cv2.imread(os.path.join(path, filename))\n",
    "        img = cv2.resize(img, img_array_size)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = np.asarray(img, dtype=np.float32)\n",
    "        img = img/225.0\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "\n",
    "    images = np.squeeze(images)\n",
    "    \n",
    "    # Load labels\n",
    "    labels_path = os.path.join(data_dir, set_name, f'{set_name}_labels.csv')\n",
    "    labels = pd.read_csv(labels_path)\n",
    "    \n",
    "    # Save features\n",
    "    features_path = os.path.join(data_dir, set_name, f'{set_name}_coughvid_melspec.npz')\n",
    "    covid_status = labels.label.values\n",
    "    features = {\n",
    "        'images': images,\n",
    "        'covid_status': covid_status        \n",
    "    }\n",
    "    np.savez(features_path, **features)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f2ae8a-acee-4b6a-ae59-0919dd546799",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_set(new_data_dir, 'train')\n",
    "save_set(new_data_dir, 'valid')\n",
    "save_set(new_data_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f304fcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the set-wise augmented train and valid sets and splits them afterwards.\n",
    "# This was done as this way the test set is still held out, but there is a larger variety\n",
    "# in the data for training which is more representation of the dataset used for the original\n",
    "# model.\n",
    "\n",
    "def load_set(data_dir, set_name):\n",
    "    path = os.path.join(data_dir, f'{set_name}_coughvid_melspec.npz')\n",
    "    features = np.load(path)\n",
    "    X = features['images']\n",
    "    y = features['covid_status']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Join train and valid sets, shuffle them and split them for workshop\n",
    "X_train, y_train = load_set(os.path.join(new_data_dir, 'train'), 'train')\n",
    "X_valid, y_valid = load_set(os.path.join(new_data_dir, 'valid'), 'valid')\n",
    "\n",
    "X = np.concatenate((X_train, X_valid))\n",
    "y = np.concatenate((y_train, y_valid))\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, stratify=y, shuffle=True, random_state=42)\n",
    "\n",
    "features = {\n",
    "        'images': X_train,\n",
    "        'covid_status': y_train        \n",
    "    }\n",
    "np.savez(os.path.join(new_data_dir, 'train.npz'), **features)\n",
    "\n",
    "features = {\n",
    "        'images': X_valid,\n",
    "        'covid_status': y_valid        \n",
    "    }\n",
    "np.savez(os.path.join(new_data_dir, 'valid.npz'), **features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
